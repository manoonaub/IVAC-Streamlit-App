# sections/conclusions.py â€” FULL BILINGUAL, DATA-DRIVEN
import streamlit as st
import pandas as pd
import numpy as np
from utils.io import load_data
from utils.prep import make_tables

TEXTS = {
    "en": {
        "language": "Language", "en": "English", "fr": "FranÃ§ais",
        "header": "ðŸ’¡ Conclusions & Insights",
        "intro": "This page synthesizes key findings from the IVAC dashboard and provides actionable recommendations for policy and practice.",

        "key_findings_title": "ðŸ” Key Findings (latest session)",
        "kf1_title": "1ï¸âƒ£ Persistent Territorial Disparities",
        "kf2_title": "2ï¸âƒ£ Public vs Private Sector Gap",
        "kf3_title": "3ï¸âƒ£ Pass Rate vs Value Added: correlation",
        "kf4_title": "4ï¸âƒ£ Stability over time (national VA)",

        "recommendations_title": "ðŸŽ¯ Policy Recommendations",
        "rec1": "**Territorial support:** Build peer-learning networks between top and Q4 regions; prioritize sustained low-VA areas.",
        "rec2": "**Contextualized evaluation:** Move beyond raw pass rates; emphasize **value added** adjusted for student background.",
        "rec3": "**Resource reallocation:** Channel funding and coaching to schools with persistently negative VA (esp. rural & high-need public).",
        "rec4": "**Best-practice sharing:** Document methods from top schools (public & private) and scale them via a national knowledge hub.",
        "rec5": "**Longitudinal monitoring:** Use multi-year panels to separate structural issues from one-off fluctuations.",
        "rec6": "**Transparency & comms:** Publish IVAC results with clear caveats (context matters; VA â‰  absolute quality).",

        "limitations_title": "âš ï¸ Limitations & Caveats",
        "lim1": "**Correlation â‰  causation.** High VA does not prove pedagogy; unobserved advantages may remain.",
        "lim2": "**Socio-economic proxies are imperfect.** Student background is complex.",
        "lim3": "**DNB is a snapshot.** It ignores creativity, critical thinking, long-term outcomes.",
        "lim4": "**Small-n volatility.** Small schools vary more; treat outliers with caution.",
        "lim5": "**Data quality varies.** Missingness, reporting errors, exam changes can affect comparability.",

        "next_steps_title": "ðŸš€ Next Steps",
        "ns1": "**Deep-dives** on top performers to isolate transferable practices.",
        "ns2": "**Qualitative work** (interviews, observations) to complement VA.",
        "ns3": "**Student trajectories** beyond DNB (HS success, dropout).",
        "ns4": "**Field experiments** in low-VA regions with rigorous evaluation.",
        "ns5": "**International benchmarking** of value-added models.",

        "final_message": """
---
### ðŸŽ“ Final thought

Data can **reveal inequalities and guide action**, but numbers alone donâ€™t transform schools â€” **people do**.
Treat this dashboard as a **starting point for dialogue**, not a final verdict.

**The goal is not to rank, but to support.**
""",

        "quick_stats": "ðŸ“Š Quick Stats",
        "stat_avg_va": "Avg VA",
        "stat_sigma": "Dispersion (Ïƒ)",
        "stat_schools": "Schools",
        "stat_pos_va": "Positive VA (%)",
    },
    "fr": {
        "language": "Langue", "en": "English", "fr": "FranÃ§ais",
        "header": "ðŸ’¡ Conclusions & Enseignements",
        "intro": "Cette page synthÃ©tise les principaux enseignements du tableau de bord IVAC et propose des recommandations actionnables pour les politiques Ã©ducatives.",

        "key_findings_title": "ðŸ” Enseignements clÃ©s (dernier millÃ©sime)",
        "kf1_title": "1ï¸âƒ£ DisparitÃ©s territoriales persistantes",
        "kf2_title": "2ï¸âƒ£ Ã‰cart Public vs PrivÃ©",
        "kf3_title": "3ï¸âƒ£ Taux de rÃ©ussite vs Valeur ajoutÃ©e : corrÃ©lation",
        "kf4_title": "4ï¸âƒ£ StabilitÃ© temporelle (VA nationale)",

        "recommendations_title": "ðŸŽ¯ Recommandations",
        "rec1": "**Soutien territorial :** RÃ©seaux d'apprentissage entre rÃ©gions leaders et Q4 ; prioriser les zones Ã  VA durablement faible.",
        "rec2": "**Ã‰valuation contextualisÃ©e :** Aller au-delÃ  des taux bruts ; mettre lâ€™accent sur la **valeur ajoutÃ©e** ajustÃ©e du contexte.",
        "rec3": "**RÃ©allocation des ressources :** Financements & coaching vers les Ã©tablissements Ã  VA nÃ©gative persistante (not. public & rural).",
        "rec4": "**Partage des pratiques :** Capitaliser les mÃ©thodes des meilleurs (publics & privÃ©s) via une base nationale.",
        "rec5": "**Suivi pluriannuel :** Panneaux multi-annÃ©es pour distinguer structurel vs conjoncturel.",
        "rec6": "**Transparence & pÃ©dagogie :** Publier IVAC avec mises en garde (le contexte compte ; VA â‰  qualitÃ© absolue).",

        "limitations_title": "âš ï¸ Limites & prÃ©cautions",
        "lim1": "**CorrÃ©lation â‰  causalitÃ©.** Une VA Ã©levÃ©e ne prouve pas la pÃ©dagogie ; des avantages non observÃ©s peuvent subsister.",
        "lim2": "**Variables socio-Ã©co imparfaites.** Le profil des Ã©lÃ¨ves est complexe.",
        "lim3": "**Le DNB est un instantanÃ©.** Il ignore crÃ©ativitÃ©, esprit critique, devenir Ã  long terme.",
        "lim4": "**VolatilitÃ© petit effectif.** Petits Ã©tablissements = variance plus forte ; prudence sur les outliers.",
        "lim5": "**QualitÃ© de donnÃ©es variable.** Valeurs manquantes, erreurs, changements dâ€™Ã©preuve nuisent Ã  la comparabilitÃ©.",

        "next_steps_title": "ðŸš€ Prochaines Ã©tapes",
        "ns1": "**Ã‰tudes approfondies** des meilleurs pour isoler les pratiques transfÃ©rables.",
        "ns2": "**Volet qualitatif** (entretiens, observations) pour complÃ©ter la VA.",
        "ns3": "**Trajectoires Ã©lÃ¨ves** au-delÃ  du DNB (rÃ©ussite au lycÃ©e, dÃ©crochage).",
        "ns4": "**ExpÃ©rimentations** en rÃ©gions Ã  VA faible avec Ã©valuation rigoureuse.",
        "ns5": "**Benchmark international** des modÃ¨les de valeur ajoutÃ©e.",

        "final_message": """
---
### ðŸŽ“ RÃ©flexion finale

Les donnÃ©es peuvent **Ã©clairer les inÃ©galitÃ©s et guider lâ€™action**, mais ce ne sont pas les chiffres qui transforment les Ã©coles â€” **ce sont les personnes**.
ConsidÃ©rez ce tableau de bord comme un **point de dÃ©part du dialogue**, pas un jugement dÃ©finitif.

**Lâ€™objectif nâ€™est pas de classer, mais de soutenir.**
""",

        "quick_stats": "ðŸ“Š Statistiques rapides",
        "stat_avg_va": "VA moyenne",
        "stat_sigma": "Dispersion (Ïƒ)",
        "stat_schools": "Ã‰tablissements",
        "stat_pos_va": "VA positive (%)",
    },
}

# =========================
def _get_lang(default="fr") -> str:
    try:
        lang = st.query_params.get("lang", default)
        return lang if lang in ("en", "fr") else default
    except Exception:
        return default
 
def _set_lang(lang: str):
    try:
        st.query_params["lang"] = lang
    except Exception:
        pass


def _fmt(x, fmt="{:.2f}", na="â€”"):
    try:
        if x is None or (isinstance(x, float) and np.isnan(x)):
            return na
        return fmt.format(x)
    except Exception:
        return na

def _safe_corr(df, a, b):
    try:
        c = df[[a, b]].corr(numeric_only=True).iloc[0, 1]
        return None if np.isnan(c) else float(c)
    except Exception:
        return None


# =========================
def show():
    current = _get_lang()
    st.sidebar.subheader(TEXTS[current]["language"])
    choice = st.sidebar.radio(
        label=" ",
        options=["en", "fr"],
        format_func=lambda x: TEXTS[x][x],
        key="lang_selector_conclusions",
        horizontal=True,
        label_visibility="collapsed",
    )
    if choice != current:
        _set_lang(choice)
        st.rerun()
    T = TEXTS[choice]

    #  Header & intro 
    st.header(T["header"])
    st.info(T["intro"])

    # Load data (robust) 
    try:
        df_raw = load_data()
        tables = make_tables(df_raw)
    except Exception as e:
        st.error(f"Data loading error: {e}")
        return

    df_over = tables.get("overview", pd.DataFrame())
    by_region = tables.get("by_region", pd.DataFrame())
    ts = tables.get("timeseries", pd.DataFrame())

    # Identify latest session if available
    session_col = "session" if "session" in df_over.columns else None
    latest_session = int(df_over[session_col].max()) if (session_col and not df_over.empty) else None
    df_latest = df_over[df_over[session_col] == latest_session] if (latest_session is not None) else df_over

    # Precompute metrics 
    mean_va = float(df_latest["valeur_ajoutee"].mean()) if "valeur_ajoutee" in df_latest.columns and not df_latest.empty else None
    mean_rate = float(df_latest["taux_reussite_g"].mean()) if "taux_reussite_g" in df_latest.columns and not df_latest.empty else None
    sigma_va = float(df_latest["valeur_ajoutee"].std()) if "valeur_ajoutee" in df_latest.columns and not df_latest.empty else None
    n_schools = int(len(df_latest)) if not df_latest.empty else 0
    pos_va_pct = float((df_latest["valeur_ajoutee"] > 0).mean() * 100) if "valeur_ajoutee" in df_latest.columns and len(df_latest) else None

    # Regions (latest)
    top_region = bottom_region = None
    top_va = bottom_va = None
    gap_va = None
    if isinstance(by_region, pd.DataFrame) and not by_region.empty and {"region_academique", "valeur_ajoutee"}.issubset(by_region.columns):
        if session_col and "session" in by_region.columns and latest_session is not None:
            reg_latest = by_region[by_region["session"] == latest_session].copy()
        else:
            reg_latest = by_region.copy()
        reg_latest = reg_latest.dropna(subset=["valeur_ajoutee"])
        if not reg_latest.empty:
            grp = reg_latest.groupby("region_academique", dropna=True)["valeur_ajoutee"].mean().sort_values(ascending=False)
            if len(grp) > 0:
                top_region, top_va = grp.index[0], float(grp.iloc[0])
                bottom_region, bottom_va = grp.index[-1], float(grp.iloc[-1])
                gap_va = top_va - bottom_va

    # Sector gap (latest)
    sector_delta = None
    p_value = None
    if "secteur" in df_latest.columns and "valeur_ajoutee" in df_latest.columns:
        pu = df_latest.loc[df_latest["secteur"] == "PU", "valeur_ajoutee"].dropna()
        pr = df_latest.loc[df_latest["secteur"] == "PR", "valeur_ajoutee"].dropna()
        if len(pu) > 3 and len(pr) > 3:
            sector_delta = float(pr.mean() - pu.mean())
            try:
                from scipy import stats
                _, p_value = stats.ttest_ind(pr, pu, equal_var=False)
                p_value = float(p_value)
            except Exception:
                p_value = None

    # Correlation (latest)
    corr_rate_va = _safe_corr(df_latest, "taux_reussite_g", "valeur_ajoutee")

    # Time trend (national VA)
    delta_va = None
    if isinstance(ts, pd.DataFrame) and not ts.empty and {"valeur_ajoutee", "session"}.issubset(ts.columns):
        ts_sorted = ts.dropna(subset=["session", "valeur_ajoutee"]).sort_values("session")
        if len(ts_sorted) >= 2:
            delta_va = float(ts_sorted["valeur_ajoutee"].iloc[-1] - ts_sorted["valeur_ajoutee"].iloc[0])
    # =========================
    st.markdown(f"## {T['key_findings_title']}")

    # Territorial disparities
    if choice == "fr":
        st.markdown(f"### {T['kf1_title']}")
        st.markdown(
            f"- **Leader** : **{top_region or 'â€”'}** ({_fmt(top_va, '{:+.2f}')}) &nbsp;â€¢&nbsp; "
            f"**Ã€ surveiller** : **{bottom_region or 'â€”'}** ({_fmt(bottom_va, '{:+.2f}')})  \n"
            f"- **Ã‰cart Topâ€“Bottom (VA)** : **{_fmt(gap_va, '{:.2f}')} pts**  \n"
            f"- **VA moyenne nationale** : **{_fmt(mean_va, '{:+.2f}')}**  "
        )
        st.caption("Lecture : un Ã©cart important entre rÃ©gions confirme des disparitÃ©s territoriales persistantes.")
    else:
        st.markdown(f"### {T['kf1_title']}")
        st.markdown(
            f"- **Leader**: **{top_region or 'â€”'}** ({_fmt(top_va, '{:+.2f}')}) &nbsp;â€¢&nbsp; "
            f"**Watch**: **{bottom_region or 'â€”'}** ({_fmt(bottom_va, '{:+.2f}')})  \n"
            f"- **Topâ€“Bottom gap (VA)**: **{_fmt(gap_va, '{:.2f}')} pts**  \n"
            f"- **National average VA**: **{_fmt(mean_va, '{:+.2f}')}**  "
        )
        st.caption("Interpretation: a large spread across regions signals persistent territorial disparities.")

    # Sector gap
    if choice == "fr":
        st.markdown(f"### {T['kf2_title']}")
        st.markdown(
            f"- **Î”(PR âˆ’ PU)** : **{_fmt(sector_delta, '{:+.2f}')} pts VA**  \n"
            f"- **SignificativitÃ© (p-value)** : **{_fmt(p_value, '{:.4f}')}** "
            + ("â†’ **diffÃ©rence significative**" if (p_value is not None and p_value < 0.05) else "â†’ diffÃ©rence non significative")
        )
        st.caption("Rappel : Ã©cart statistique â‰  causalitÃ© (sÃ©lection, contexte).")
    else:
        st.markdown(f"### {T['kf2_title']}")
        st.markdown(
            f"- **Î”(PR âˆ’ PU)**: **{_fmt(sector_delta, '{:+.2f}')} VA pts**  \n"
            f"- **Significance (p-value)**: **{_fmt(p_value, '{:.4f}')}** "
            + ("â†’ **significant difference**" if (p_value is not None and p_value < 0.05) else "â†’ not significant")
        )
        st.caption("Reminder: statistical gap â‰  causality (selection, context).")

    # Correlation pass rate vs VA
    if choice == "fr":
        st.markdown(f"### {T['kf3_title']}")
        if corr_rate_va is None:
            st.markdown("CorrÃ©lation non calculable sur le dernier millÃ©sime.")
        else:
            st.markdown(f"- **CorrÃ©lation de Pearson (taux vs VA)** : **{corr_rate_va:.2f}**")
            st.caption(
                "Si |r| > 0,5 â†’ relation forte ; ~0,3 â†’ modÃ©rÃ©e ; < 0,2 â†’ faible. "
                "Association â‰  causalitÃ©."
            )
    else:
        st.markdown(f"### {T['kf3_title']}")
        if corr_rate_va is None:
            st.markdown("Correlation not computable on latest vintage.")
        else:
            st.markdown(f"- **Pearson correlation (rate vs VA)**: **{corr_rate_va:.2f}**")
            st.caption(
                "If |r| > 0.5 â†’ strong; ~0.3 â†’ moderate; < 0.2 â†’ weak. "
                "Association â‰  causation."
            )

    # Stability over time
    if choice == "fr":
        st.markdown(f"### {T['kf4_title']}")
        st.markdown(
            f"- **Î” VA nationale (dÃ©but â†’ fin)** : **{_fmt(delta_va, '{:+.2f}')} pts**  \n"
            f"- **VA moyenne (dernier millÃ©sime)** : **{_fmt(mean_va, '{:+.2f}')}**"
        )
        st.caption("Par construction, la VA nationale oscille autour de 0 ; suivre lâ€™Ã©volution multi-annuelle reste essentiel.")
    else:
        st.markdown(f"### {T['kf4_title']}")
        st.markdown(
            f"- **Î” National VA (first â†’ last)**: **{_fmt(delta_va, '{:+.2f}')} pts**  \n"
            f"- **Avg VA (latest)**: **{_fmt(mean_va, '{:+.2f}')}**"
        )
        st.caption("By design, national VA hovers around 0; multi-year tracking is still essential.")

    # Recommendations, limitations, next steps 
    st.markdown("---")
    st.markdown(f"## {T['recommendations_title']}")
    st.markdown(f"1. {T['rec1']}")
    st.markdown(f"2. {T['rec2']}")
    st.markdown(f"3. {T['rec3']}")
    st.markdown(f"4. {T['rec4']}")
    st.markdown(f"5. {T['rec5']}")
    st.markdown(f"6. {T['rec6']}")

    st.markdown("---")
    st.markdown(f"## {T['limitations_title']}")
    st.warning(
        "- " + T["lim1"] + "\n\n"
        "- " + T["lim2"] + "\n\n"
        "- " + T["lim3"] + "\n\n"
        "- " + T["lim4"] + "\n\n"
        "- " + T["lim5"]
    )

    st.markdown("---")
    st.markdown(f"## {T['next_steps_title']}")
    st.markdown(f"- {T['ns1']}")
    st.markdown(f"- {T['ns2']}")
    st.markdown(f"- {T['ns3']}")
    st.markdown(f"- {T['ns4']}")
    st.markdown(f"- {T['ns5']}")

    st.markdown(T["final_message"])

    # Quick stats (optional footer)
    if not df_latest.empty and "valeur_ajoutee" in df_latest.columns:
        st.markdown("---")
        st.markdown(f"### {T['quick_stats']}")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric(T["stat_avg_va"], _fmt(mean_va, "{:+.2f}"))
        col2.metric(T["stat_sigma"], _fmt(sigma_va, "{:.2f}"))
        col3.metric(T["stat_schools"], f"{n_schools:,}")
        col4.metric(T["stat_pos_va"], _fmt(pos_va_pct, "{:.1f}%"))